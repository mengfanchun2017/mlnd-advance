{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice: Statistical Significance\n",
    "\n",
    "Let's say that we've collected data for a web-based experiment. In the experiment, we're testing the change in layout of a product information page to see if this affects the proportion of people who click on a button to go to the download page. This experiment has been designed to have a cookie-based diversion, and we record two things from each user: which page version they received, and whether or not they accessed the download page during the data recording period. (We aren't keeping track of any other factors in this example, such as number of pageviews, or time between accessing the page and making the download, that might be of further interest.)\n",
    "\n",
    "Your objective in this notebook is to perform a statistical test on both recorded metrics to see if there is a statistical difference between the two groups.\n",
    "\n",
    "假设我们为一项网络实验收集了数据。在实验中，我们检验了产品信息页的布局变化，看看这种变化是否会影响到点击按钮并转到下载页的用户所占的比例。该实验以 Cookie 为分组依据，我们记录了用户的两项数据：他们访问的是哪个网页版本，以及在数据记录阶段是否访问了下载页。（在此示例中，我们没有跟踪任何其他因素，例如页面查看次数，或从访问网页到下载产品的时间间隔，这些因素可能值得进一步研究。）\n",
    "\n",
    "在此 notebook 中，你的目标是对这两个记录指标执行统计学检验，看看两组之间是否存在统计学差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T08:58:08.125103Z",
     "start_time": "2019-12-21T08:58:08.114602Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats import proportion as proptests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T08:58:08.605009Z",
     "start_time": "2019-12-21T08:58:08.591369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   condition  click\n",
       "0          1      0\n",
       "1          0      0\n",
       "2          0      0\n",
       "3          1      1\n",
       "4          1      0\n",
       "5          1      0\n",
       "6          0      0\n",
       "7          1      1\n",
       "8          0      0\n",
       "9          1      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "# data = pd.read_csv('../data/statistical_significance_data.csv')\n",
    "data = pd.read_csv('data/statistical_significance_data.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, the 'condition' column takes a 0 for the control group, and 1 for the experimental group. The 'click' column takes a values of 0 for no click, and 1 for a click.\n",
    "\n",
    "在数据集的“condition”列中，0 表示对照组，1 表示实验组。对于“click”列，0 表示没有点击，1 表示点击了。\n",
    "\n",
    "## Checking the Invariant Metric\n",
    "\n",
    "First of all, we should check that the number of visitors assigned to each group is similar. It's important to check the invariant metrics as a prerequisite so that our inferences on the evaluation metrics are founded on solid ground. If we find that the two groups are imbalanced on the invariant metric, then this will require us to look carefully at how the visitors were split so that any sources of bias are accounted for. It's possible that a statistically significant difference in an invariant metric will require us to revise random assignment procedures and re-do data collection.\n",
    "\n",
    "In this case, we want to do a two-sided hypothesis test on the proportion of visitors assigned to one of our conditions. Choosing the control or the experimental condition doesn't matter: you'll get the same result either way. Feel free to use whatever method you'd like: we'll highlight two main avenues below.\n",
    "\n",
    "If you want to take a simulation-based approach, you can simulate the number of visitors that would be assigned to each group for the number of total observations, assuming that we have an expected 50/50 split. Do this many times (200 000 repetitions should provide a good speed-variability balance in this case) and then see in how many simulated cases we get as extreme or more extreme a deviation from 50/50 that we actually observed. Don't forget that, since we have a two-sided test, an extreme case also includes values on the opposite side of 50/50. (e.g. Since simulated outcomes of .48 and lower are considered as being more extreme than an actual observation of 0.48, so too will simulated outcomes of .52 and higher.) The proportion of flagged simulation outcomes gives us a p-value on which to assess our observed proportion. We hope to see a larger p-value, insufficient evidence to reject the null hypothesis.\n",
    "\n",
    "If you want to take an analytic approach, you could use the exact binomial distribution to compute a p-value for the test. The more usual approach, however, is to use the normal distribution approximation. Recall that this is possible thanks to our large sample size and the central limit theorem. To get a precise p-value, you should also perform a \n",
    "continuity correction, either adding or subtracting 0.5 to the total count before computing the area underneath the curve. (e.g. If we had 415 / 850 assigned to the control group, then the normal approximation would take the area to the left of $(415 + 0.5) / 850 = 0.489$ and to the right of $(435 - 0.5) / 850 = 0.511$.)\n",
    "\n",
    "You can check your results by completing the quiz and watching the video following the workspace. You could also try using multiple approaches and seeing if they come up with similar outcomes!\n",
    "\n",
    "## 检查不变指标\n",
    "\n",
    "首先，我们应该检查分配给每组的用户人数是否差不多。务必要检查作为前提条件的不变指标，这样可以保证根据评估指标做出的推断有扎实的依据。如果我们发现两组在不变指标方面不平衡，则需要仔细观察访问者的划分方式，看看能否找出任何偏差原因。如果发现不变指标存在统计学显著性差异，则可能需要修改随机分配流程，并重新收集数据。\n",
    "\n",
    "在这种情形下，我们需要对分配给某个条件的访问者比例进行双边假设检验。选择对照组还是实验组并不重要：你会获得相同的结果。你可以选择使用任何一种方法，我们将在下面主要介绍两种方法。\n",
    "\n",
    "如果你想采用模拟方法，你可以模拟分配到每组的访问者人数，假设按照 50/50 的比例划分。重复这一过程很多次（在此示例中，重复 200 000 次应该会达到很好的速度可变性平衡），然后看看有多少模拟情形完全偏离了 50/50 的分配结果。注意，由于我们完成的是双边检验，因此极端情况还包括 50/50 相反情形的值。（例如，由于 0.48 及更低的模拟结果被视为比 0.48 的实际观测值更极端，所以 0.52 及更高的模拟结果也一样。）我们可以根据被标记模拟结果的比例获得 p 值，并用p 值评估观察到的比例。我们希望看到更大的 p 值，表明拒绝零假设的证据不足。\n",
    "\n",
    "如果你想采取分析方法，可以使用精确二项分布计算检验的 p 值。但是，更常见的方法是使用正态分布逼近法。由于样本量很大，并且存在中心极限定理，因此这种逼近法是可行的。要获得精确的 p 值，还应该进行连续校正， \n",
    "在计算曲线下面积之前，使总数加上或减去 0.5。（例如，如果对照组的分配比例是 415 / 850，那么正态逼近计算的面积向左为 $(415 + 0.5) / 850 = 0.489$，向右为 $(435 - 0.5) / 850 = 0.511$。）\n",
    "\n",
    "完成下面的 workspace 后，你可以查看下个页面的解答内容。你还可以尝试多种方法，看看它们是否会取得相似的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T08:58:10.479731Z",
     "start_time": "2019-12-21T08:58:10.469122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 491)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of trials and number of 'successes'\n",
    "n_obs = data.shape[0]\n",
    "n_control = data.groupby('condition').size()[0]\n",
    "n_obs, n_control\n",
    "# obs 是所有数据，control是控制组数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T08:58:55.915125Z",
     "start_time": "2019-12-21T08:58:55.901459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.803480629279107\n",
      "-0.5062175977346661\n",
      "0.6127039025537114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15865525393145707"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute a z-score and p-value\n",
    "p = 0.5\n",
    "# 2项分布的sd是 p(1-P)n\n",
    "sd = np.sqrt(p * (1-p) * n_obs)\n",
    "# z按照上面提示的调整0.5\n",
    "z = ((n_control + 0.5) - p * n_obs) / sd\n",
    "\n",
    "print(sd)\n",
    "print(z)\n",
    "# 从最后的代码, 这里就是看数据在 +- 0.5 sigema 之外(一个标准差之间)的概率是多少(代码有些简化)\n",
    "print(2 * stats.norm.cdf(z))\n",
    "# 正态分布,z小于-1的累积面积\n",
    "stats.norm.cdf(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:03:27.042546Z",
     "start_time": "2019-12-21T09:03:27.032698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001780020604345"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_std = np.std(data['condition'],ddof=1)\n",
    "arr_std\n",
    "# ddof 是 n 减去的数量，sample的时候是用 n-1 进行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:08:04.329632Z",
     "start_time": "2019-12-21T09:08:04.319465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 491)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of trials and number of 'successes'\n",
    "n_obs = data.shape[0]\n",
    "n_control = data.groupby('condition').size()[0]\n",
    "n_obs, n_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:15:51.495269Z",
     "start_time": "2019-12-21T09:15:51.458318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61172\n",
      "0.3053\n",
      "0.30642\n"
     ]
    }
   ],
   "source": [
    "# # simulate outcomes under null, compare to observed outcome\n",
    "p = 0.5\n",
    "n_trials = 200000\n",
    "\n",
    "samples = np.random.binomial(n_obs, p, n_trials)\n",
    "# 模拟了 20w 次\n",
    "\n",
    "print(np.logical_or(samples <= n_control, samples >= (n_obs - n_control)).mean())\n",
    "\n",
    "# 上面是检查比491小的和比508大的概率只和，应该是就是随便检查下，可以分别看下值\n",
    "print((samples <= n_control).mean())\n",
    "print((samples >= (n_obs - n_control)).mean())\n",
    "\n",
    "## samples 是模拟出来的数量\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Evaluation Metric\n",
    "\n",
    "After performing our checks on the invariant metric, we can move on to performing a hypothesis test on the evaluation metric: the click-through rate. In this case, we want to see that the experimental group has a significantly larger click-through rate than the control group, a one-tailed test.\n",
    "\n",
    "The simulation approach for this metric isn't too different from the approach for the invariant metric. You'll need the overall click-through rate as the common proportion to draw simulated values from for each group. You may also want to perform more simulations since there's higher variance for this test.\n",
    "\n",
    "There's a few analytic approaches possible here, but you'll probably make use of the normal approximation again in these cases. In addition to the pooled click-through rate, you'll need a pooled standard deviation in order to compute a z-score. While there is a continuity correction possible in this case as well, it's much more conservative than the p-value that a simulation will usually imply. Computing the z-score and resulting p-value without a continuity correction should be closer to the simulation's outcomes, though slightly more optimistic about there being a statistical difference between groups.\n",
    "\n",
    "As with the previous question, you'll find a quiz and video following the workspace for you to check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:16:13.884610Z",
     "start_time": "2019-12-21T09:16:13.871611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "0    0.079430\n",
       "1    0.112205\n",
       "Name: click, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_click = data.groupby('condition').mean()['click']\n",
    "p_click\n",
    "# 可以看出 click 两组还是差别挺大的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:20:26.262650Z",
     "start_time": "2019-12-21T09:20:26.251784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4126287098728043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.03277498917523293"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再增加个百分比比较直观，提高了 40%\n",
    "display((p_click[1] - p_click[0])/p_click[0])\n",
    "p_click[1] - p_click[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:21:54.197166Z",
     "start_time": "2019-12-21T09:21:54.179014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491, 508, 0.0960960960960961)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of trials and overall 'success' rate under null\n",
    "n_control = data.groupby('condition').size()[0]\n",
    "n_exper = data.groupby('condition').size()[1]\n",
    "p_null = data['click'].mean()\n",
    "n_control, n_exper, p_null\n",
    "# 这里输出的是 控制组、实验组的数量、总体平均 click 率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:37:30.441109Z",
     "start_time": "2019-12-21T09:37:30.434618Z"
    }
   },
   "outputs": [],
   "source": [
    "# DROP! 跳过本cell\n",
    "# compute standard error, z-score, and p-value\n",
    "## 首先公式错了，sd的公式最右面是乘n，不是1/n。前面的是正确的\n",
    "## 错误 se_p = np.sqrt(p_null * (1-p_null) * (1/n_control + 1/n_exper)) 输出为0.0x，数量级不对\n",
    "## 正确 se_p = np.sqrt(p_null * (1-p_null) * (n_control + n_exper)) 输出为 9.31 数量级ok\n",
    "# 本 cell 分析不对，应该是对应每一个组（control）或者（exp）来看分布，而不是把两个组做比较\n",
    "## 所以 z = (p_click[1] - p_click[0]) / se_p 完全不对\n",
    "# print(z)\n",
    "#print(1-stats.norm.cdf(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:44:34.755351Z",
     "start_time": "2019-12-21T09:44:34.741418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "0    491\n",
       "1    508\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('condition').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:52:56.394765Z",
     "start_time": "2019-12-21T09:52:56.378875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491, 508, 0.0960960960960961)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of trials and overall 'success' rate under null\n",
    "n_control = data.groupby('condition').size()[0]\n",
    "n_exper = data.groupby('condition').size()[1]\n",
    "p_null = data['click'].mean()\n",
    "# 上面的是我们计算出来的数据值，用于后续比较\n",
    "n_control,n_exper,p_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:53:12.667075Z",
     "start_time": "2019-12-21T09:53:12.658313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00103036,  0.00833507, -0.00123483, ..., -0.0353128 ,\n",
       "       -0.00551261,  0.03107911])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:55:16.216416Z",
     "start_time": "2019-12-21T09:55:15.748393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0395475\n"
     ]
    }
   ],
   "source": [
    "# simulate outcomes under null, compare to observed outcome\n",
    "n_trials = 2000000\n",
    "\n",
    "ctrl_clicks = np.random.binomial(n_control, p_null, n_trials)\n",
    "exp_clicks = np.random.binomial(n_exper, p_null, n_trials)\n",
    "samples = exp_clicks / n_exper - ctrl_clicks / n_control\n",
    "## sample 就是看exp组click和control组的差别是多少\n",
    "## 原solution的20万次浮动有点大，多加个0就比较稳定在0.39了少了循环\n",
    "\n",
    "print((samples >= (p_click[1] - p_click[0])).mean())\n",
    "# 输出的是20w次模拟点击率差异的平均值\n",
    "# 实际值为0.0327，之所以不一样是因为 ctrl_clicks 和 exp_click 模拟的时候是按照 p_null 做的模拟（平均值），而不是各自组别的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T09:58:25.534729Z",
     "start_time": "2019-12-21T09:58:25.050142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002085\n"
     ]
    }
   ],
   "source": [
    "# 测试，如果换乘数据中的值则几乎为零\n",
    "n_trials = 2000000\n",
    "\n",
    "ctrl_clicks = np.random.binomial(n_control, p_click[1], n_trials)\n",
    "exp_clicks = np.random.binomial(n_exper, p_click[0], n_trials)\n",
    "samples = exp_clicks / n_exper - ctrl_clicks / n_control\n",
    "## sample 就是看exp组click和control组的差别是多少\n",
    "## 原solution的20万次浮动有点大，多加个0就比较稳定在0.39了少了循环\n",
    "\n",
    "print((samples >= (p_click[1] - p_click[0])).mean())\n",
    "# 输出的是20w次模拟点击率差异的平均值\n",
    "# 本节结束，主要是熟悉点击率的计算，模拟的使用和一些统计学公式的实现。具体问题在后续会深入。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
